{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from starter import *\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "holidays = pd.read_csv('holidays.csv')\n",
    "weather = pd.read_csv('weather.csv')\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "submission_format = pd.read_csv('submission_format.csv')\n",
    "submission_frequency = pd.read_csv('submission_frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_frequency = pickle.load(open('submission_frequency.p', 'rb'))\n",
    "metadata = pickle.load(open('metadata.p', 'rb'))\n",
    "holidays = pickle.load(open('holidays.p', 'rb'))\n",
    "weather_grouped = pickle.load(open('weather_grouped.p', 'rb'))\n",
    "train = pickle.load(open('train.p', 'rb'))\n",
    "submission_format = pickle.load(open('submission_format.p', 'rb'))\n",
    "df = pickle.load(open('df.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Holiday'].fillna(0, inplace=True)\n",
    "df['isHoliday'].fillna(0, inplace=True)\n",
    "df.drop(['Unnamed: 0_x','Unnamed: 0_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>SiteId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Value</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>isHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744519</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>9.096555e+05</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>19.60</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7627564</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>1.748273e+06</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>21.30</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7034705</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>23.35</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5995486</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>21.60</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7326510</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>15.80</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_id  SiteId  Timestamp         Value        Date      Time  Hour  \\\n",
       "0   744519       1 2014-09-03  9.096555e+05  2014-09-03  00:00:00     0   \n",
       "1  7627564       1 2014-09-04  1.748273e+06  2014-09-04  00:00:00     0   \n",
       "2  7034705       1 2014-09-05  0.000000e+00  2014-09-05  00:00:00     0   \n",
       "3  5995486       1 2014-09-06  0.000000e+00  2014-09-06  00:00:00     0   \n",
       "4  7326510       1 2014-09-07  0.000000e+00  2014-09-07  00:00:00     0   \n",
       "\n",
       "   DayofWeek  Year  Month  Temperature   Distance  Holiday  isHoliday  \n",
       "0  Wednesday  2014      9        19.60  22.921092        0        0.0  \n",
       "1   Thursday  2014      9        21.30  22.921092        0        0.0  \n",
       "2     Friday  2014      9        23.35  22.921092        0        0.0  \n",
       "3   Saturday  2014      9        21.60  22.921092        0        0.0  \n",
       "4     Sunday  2014      9        15.80  22.921092        0        0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>ForecastPeriodNS</th>\n",
       "      <th>ForecastPeriodMin</th>\n",
       "      <th>Period_Quarter</th>\n",
       "      <th>Period_Hour</th>\n",
       "      <th>Period_Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3600000000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastId  ForecastPeriodNS  ForecastPeriodMin  Period_Quarter  \\\n",
       "0           1    86400000000000             1440.0               0   \n",
       "1           2    86400000000000             1440.0               0   \n",
       "2           3    86400000000000             1440.0               0   \n",
       "3           4    86400000000000             1440.0               0   \n",
       "4           5     3600000000000               60.0               0   \n",
       "\n",
       "   Period_Hour  Period_Days  \n",
       "0            0            1  \n",
       "1            0            1  \n",
       "2            0            1  \n",
       "3            0            1  \n",
       "4            1            0  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align SiteId to ForecastId\n",
    "id_align = submission_format.groupby(by = 'ForecastId').mean()\n",
    "id_align['ForecastId'] = id_align.index\n",
    "id_align.drop(['obs_id', 'Value'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge SiteId to ForecastId\n",
    "submission_frequency = submission_frequency.merge(id_align, how='left', on='ForecastId')\n",
    "site_type = submission_frequency.groupby(by='SiteId').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteId</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Sampling</th>\n",
       "      <th>BaseTemperature</th>\n",
       "      <th>MondayIsDayOff</th>\n",
       "      <th>TuesdayIsDayOff</th>\n",
       "      <th>WednesdayIsDayOff</th>\n",
       "      <th>ThursdayIsDayOff</th>\n",
       "      <th>FridayIsDayOff</th>\n",
       "      <th>SaturdayIsDayOff</th>\n",
       "      <th>SundayIsDayOff</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SiteId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1387.205119</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6098.278376</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10556.293605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12541.181277</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9150.195373</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SiteId       Surface  Sampling  BaseTemperature MondayIsDayOff  \\\n",
       "SiteId                                                                   \n",
       "1            1   1387.205119      15.0             18.0              0   \n",
       "2            2   6098.278376      30.0             18.0              0   \n",
       "3            3  10556.293605       5.0             18.0              0   \n",
       "5            5  12541.181277      30.0             18.0              0   \n",
       "6            6   9150.195373      30.0             18.0              0   \n",
       "\n",
       "       TuesdayIsDayOff WednesdayIsDayOff ThursdayIsDayOff  FridayIsDayOff  \\\n",
       "SiteId                                                                      \n",
       "1                    0                 0                0               0   \n",
       "2                    0                 0                0               0   \n",
       "3                    0                 0                0               0   \n",
       "5                    0                 0                0               0   \n",
       "6                    0                 0                0               0   \n",
       "\n",
       "        SaturdayIsDayOff  SundayIsDayOff  Temperature  \n",
       "SiteId                                                 \n",
       "1                      1               1            0  \n",
       "2                      1               1            0  \n",
       "3                      1               0            0  \n",
       "5                      1               1            0  \n",
       "6                      1               1            0  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire siteid data\n",
    "def get_site_data(data=None, site_id=None, features=['Value','Temperature']):\n",
    "    df = data[data.SiteId==site_id]\n",
    "    df.index = df.Timestamp\n",
    "    df = df[features]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment and interpolate data\n",
    "def prepare_site(data=None, site_id=None, features= ['Value', 'Temperature'], method='linear'):\n",
    "    df = get_site_data(data, site_id, features)\n",
    "    try:\n",
    "        # start where there isn't consecutive NaNs\n",
    "        start_index = df[(df.Temperature.isnull()==False)&(df.Temperature.shift(-1).isnull()==False)].index[0]\n",
    "        df = df.loc[start_index:,:]\n",
    "        df['Temperature'].interpolate(method, inplace=True)\n",
    "    except:\n",
    "        print('No temperature data')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=prepare_site(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_master_data(data=None, sites=None, features=['Value', 'Temperature'], method='linear'):\n",
    "    master_df = pd.DataFrame()\n",
    "    for site in sites:\n",
    "        threshold_size = data[data.SiteId==site].shape[0]*0.5\n",
    "        site_features = features.copy()\n",
    "        if data[data.SiteId==site].Temperature.isnull().value_counts()[0] < threshold_size:\n",
    "            site_features.remove('Temperature')\n",
    "        df = prepare_site(data, site, site_features)\n",
    "        print('Finished site {} with rows {}'.format(site, df.shape[0]))\n",
    "        master_df = pd.concat([master_df, df], axis=0)\n",
    "    print('Final rows: {}'.format(master_df.shape[0]))\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and reframe features\n",
    "def reframe_features(data=None, n_in=1):\n",
    "    values = data.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, n_in, 1)\n",
    "    reframed.drop(reframed.columns[[reframed.shape[1] - i for i in range(1,data.shape[1])]], axis=1, inplace=True)\n",
    "    print(reframed.head())\n",
    "    return reframed, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-2)  var2(t-2)  var1(t-1)  var2(t-1)   var1(t)\n",
      "2   0.201850   0.763602   0.222406   0.769231  0.215942\n",
      "3   0.222406   0.769231   0.215942   0.769231  0.180349\n",
      "4   0.215942   0.769231   0.180349   0.795497  0.167053\n",
      "5   0.180349   0.795497   0.167053   0.769231  0.179651\n",
      "6   0.167053   0.769231   0.179651   0.769231  0.157865\n"
     ]
    }
   ],
   "source": [
    "reframed_data = reframe_features(df2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train/test sets from reframed data\n",
    "def split_train_test_val(reframed):\n",
    "    values = reframed.values\n",
    "    n_train_days = int(len(values) * 0.7)\n",
    "    train = values[:n_train_days, :]\n",
    "    test = values[n_train_days:, :]\n",
    "    # Split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    # Reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24283, 1, 4) (24283,) (10407, 1, 4) (10407,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = split_train_test_val(reframed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build multivariate LSTM model with validation\n",
    "def create_LSTM_val(train_X=None, train_y=None, test_X=None, test_y=None, epochs=50, batch_size=100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=epochs,\n",
    "                                batch_size=batch_size, validation_data=(test_X, test_y),\n",
    "                                verbose=1, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24283 samples, validate on 10407 samples\n",
      "Epoch 1/50\n",
      "24283/24283 [==============================] - 3s 108us/step - loss: 0.0663 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0201 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0122 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "24283/24283 [==============================] - 1s 24us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "24283/24283 [==============================] - 1s 24us/step - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "24283/24283 [==============================] - 1s 29us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "24283/24283 [==============================] - 1s 28us/step - loss: 0.0030 - val_loss: 9.6923e-04\n",
      "Epoch 24/50\n",
      "24283/24283 [==============================] - 1s 28us/step - loss: 0.0029 - val_loss: 8.8340e-04\n",
      "Epoch 25/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0029 - val_loss: 8.2869e-04\n",
      "Epoch 26/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0029 - val_loss: 7.9435e-04\n",
      "Epoch 27/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0028 - val_loss: 7.7247e-04\n",
      "Epoch 28/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.5807e-04\n",
      "Epoch 29/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0028 - val_loss: 7.4824e-04\n",
      "Epoch 30/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.4129e-04\n",
      "Epoch 31/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.3627e-04\n",
      "Epoch 32/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0028 - val_loss: 7.3259e-04\n",
      "Epoch 33/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2990e-04\n",
      "Epoch 34/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0028 - val_loss: 7.2796e-04\n",
      "Epoch 35/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2659e-04\n",
      "Epoch 36/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0028 - val_loss: 7.2566e-04\n",
      "Epoch 37/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2506e-04\n",
      "Epoch 38/50\n",
      "24283/24283 [==============================] - 1s 26us/step - loss: 0.0028 - val_loss: 7.2472e-04\n",
      "Epoch 39/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2456e-04\n",
      "Epoch 40/50\n",
      "24283/24283 [==============================] - 1s 29us/step - loss: 0.0028 - val_loss: 7.2456e-04\n",
      "Epoch 41/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2466e-04\n",
      "Epoch 42/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0028 - val_loss: 7.2483e-04\n",
      "Epoch 43/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2507e-04\n",
      "Epoch 44/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2534e-04\n",
      "Epoch 45/50\n",
      "24283/24283 [==============================] - 1s 24us/step - loss: 0.0028 - val_loss: 7.2564e-04\n",
      "Epoch 46/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2595e-04\n",
      "Epoch 47/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2627e-04\n",
      "Epoch 48/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2660e-04\n",
      "Epoch 49/50\n",
      "24283/24283 [==============================] - 1s 26us/step - loss: 0.0028 - val_loss: 7.2692e-04\n",
      "Epoch 50/50\n",
      "24283/24283 [==============================] - 1s 26us/step - loss: 0.0028 - val_loss: 7.2724e-04\n"
     ]
    }
   ],
   "source": [
    "multi_model = create_LSTM_val(train_X, train_y, test_X, test_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = multi_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare forecast to actual\n",
    "def forecast_score(pred, actual_input, actual_output):\n",
    "    actual_input = actual_input.reshape((actual_input.shape[0], actual_input.shape[2]))\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    inv_pred = np.concatenate((pred, actual_input[:, 1:]), axis=1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(inv_pred)\n",
    "    inv_pred = scaler.inverse_transform(inv_pred)\n",
    "    inv_pred = inv_pred[:,0]\n",
    "    \n",
    "    # Invert scaling for actual\n",
    "    actual_output = actual_output.reshape((len(actual_output), 1))\n",
    "    inv_output = np.concatenate((actual_output, actual_input[:, 1:]), axis=1)\n",
    "    inv_output = scaler.inverse_transform(inv_output)\n",
    "    inv_output = inv_output[:,0]\n",
    "    rmsle = RMSE(inv_output, inv_pred)\n",
    "    \n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016920891150341268"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_score(yhat, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for site prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>SiteId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Value</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayofWeek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1583559</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-18</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2071107</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-19</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1253673</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2325727</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-21</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4834576</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-08-22</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      obs_id  SiteId  Timestamp  ForecastId  Value        Date  Year  Month  \\\n",
       "180  1583559       1 2017-08-18           4    0.0  2017-08-18  2017      8   \n",
       "181  2071107       1 2017-08-19           4    0.0  2017-08-19  2017      8   \n",
       "182  1253673       1 2017-08-20           4    0.0  2017-08-20  2017      8   \n",
       "183  2325727       1 2017-08-21           4    0.0  2017-08-21  2017      8   \n",
       "184  4834576       1 2017-08-22           4    0.0  2017-08-22  2017      8   \n",
       "\n",
       "         Time  Hour DayofWeek  \n",
       "180  00:00:00     0    Friday  \n",
       "181  00:00:00     0  Saturday  \n",
       "182  00:00:00     0    Sunday  \n",
       "183  00:00:00     0    Monday  \n",
       "184  00:00:00     0   Tuesday  "
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_format[submission_format.ForecastId==4].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate train and test sets\n",
    "def load_site(train=None, test=None, site_id=None, weather=weather_grouped, holidays=holidays):\n",
    "    train = train[train.SiteId==site_id]\n",
    "    test = test[test.SiteId==site_id]\n",
    "    train.loc[:,'ForecastId'] = 0\n",
    "    data = pd.concat([train, test], axis=0)\n",
    "    data = data.merge(weather, how='left', on=['Timestamp', 'SiteId'])\n",
    "    data = data.merge(holidays, how='left', on=['Date','SiteId'])\n",
    "    data['Holiday'].fillna(0, inplace=True)\n",
    "    data['isHoliday'].fillna(0, inplace=True)\n",
    "    data.drop(['Unnamed: 0_x','Unnamed: 0_y'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find start and end times for site\n",
    "def find_start_end(data):\n",
    "    time_pairs = []\n",
    "    forecast_ids = data.ForecastId.unique()[1:]\n",
    "    forecast_length = data[data.ForecastId==forecast_ids[0]].shape[0]-1\n",
    "    timedelta = data.Timestamp[1] - data.Timestamp[0]\n",
    "    train_start = data.Timestamp[0]\n",
    "    test_end = data[data.ForecastId==forecast_ids[0]].Timestamp[forecast_length]\n",
    "    test_start = test_end - forecast_length*timedelta\n",
    "    train_end = test_start - timedelta\n",
    "    time_pairs.append((train_start, train_end, test_start, test_end))\n",
    "    \n",
    "    for forecast_id in forecast_ids[1:]:\n",
    "        forecast_length = data[data.ForecastId==forecast_id].shape[0]-1\n",
    "        train_start = test_end + timedelta\n",
    "        test_end = data[data.ForecastId==forecast_id].Timestamp[forecast_length]\n",
    "        test_start = test_end - forecast_length*timedelta\n",
    "        train_end = test_start - timedelta\n",
    "        time_pairs.append((train_start, train_end, test_start, test_end))\n",
    "    \n",
    "    return time_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = load_site(train, submission_format, 1)\n",
    "df1.sort_values('Timestamp', inplace=True)\n",
    "df1.index = df1.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_pairs = find_start_end(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = df1[(df1.Timestamp >= time_pairs[0][0]) & (df1.Timestamp <= time_pairs[0][3])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df302 = load_site(train, submission_format, 302)\n",
    "df302.sort_values('Timestamp', inplace=True)\n",
    "df302.index = df302.Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df302 = prepare_data(df302, features=['Value', 'Temperature','isHoliday','ForecastId','Timestamp'])\n",
    "time_pairs302 = find_start_end(df302)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# segment and interpolate data for site\n",
    "def prepare_data(data=None, features= ['Value', 'Temperature'], method='linear'):\n",
    "    data.index = data.Timestamp\n",
    "    data = data[features]\n",
    "    try:\n",
    "        # start where there isn't consecutive NaNs\n",
    "        start_index = data[(data.Temperature.isnull()==False)&(data.Temperature.shift(-1).isnull()==False)].index[0]\n",
    "        data = data.loc[start_index:,:]\n",
    "        data['Temperature'].interpolate(method, inplace=True)\n",
    "    except:\n",
    "        print('No temperature data')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment and interpolate data for site\n",
    "def prepare_data(data=None, features= ['Value', 'Temperature'], method='linear'):\n",
    "    data.index = data.Timestamp\n",
    "    data = data[features]\n",
    "    data['Temperature'].interpolate(method, inplace=True)\n",
    "    try:\n",
    "        # start where there isn't consecutive NaNs\n",
    "        start_index = data[(data.Temperature.isnull()==False)&(data.Temperature.shift(-1).isnull()==False)].index[0]\n",
    "        data = data.loc[start_index:,:]\n",
    "    except:\n",
    "        print('No temperature data')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the original function up top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize and reframe features\n",
    "def reframe_features(data=None, n_in=1):\n",
    "    values = data.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, n_in, 1)\n",
    "    reframed.drop(reframed.columns[[reframed.shape[1] - i for i in range(1,data.shape[1])]], axis=1, inplace=True)\n",
    "    print(reframed.head())\n",
    "    return reframed, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "#     if dropnan:\n",
    "#         agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = prepare_data(df1_1, features=['Value','Temperature','isHoliday', 'ForecastId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1.loc[:,'Timestamp'] = df1_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Value', 'Temperature', 'isHoliday', 'ForecastId', 'Timestamp'], dtype='object')"
      ]
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-2)  var2(t-2)  var3(t-2)  var1(t-1)  var2(t-1)  var3(t-1)   var1(t)\n",
      "0        NaN        NaN        NaN        NaN        NaN        NaN  0.091209\n",
      "1        NaN        NaN        NaN   0.091209   0.846487        0.0  0.175295\n",
      "2   0.091209   0.846487        0.0   0.175295   0.883243        0.0  0.000000\n",
      "3   0.175295   0.883243        0.0   0.000000   0.927568        0.0  0.000000\n",
      "4   0.000000   0.927568        0.0   0.000000   0.889730        0.0  0.000000\n"
     ]
    }
   ],
   "source": [
    "df1_1.drop(['ForecastId','Timestamp'],axis=1, inplace=True)\n",
    "n_train_days = df1_1[(df1_1.index >=time_pairs[0][0]) & (df1_1.index <=time_pairs[0][1])].shape[0]-1\n",
    "n_features = df1_1.shape[1]\n",
    "reframed_data, scaler = reframe_features(df1_1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359, 3)"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train_days, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train/test sets from reframed data\n",
    "def split_train_test(reframed, n_train_days):\n",
    "    values = reframed.values\n",
    "    train = values[:n_train_days, :]\n",
    "    test = values[n_train_days+1:, :]\n",
    "    # Split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    # Reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build multivariate LSTM model for predictions\n",
    "def create_LSTM(train_X=None, train_y=None, epochs=50, batch_size=100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=1, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359, 6) (359,) (60, 6) (60,)\n",
      "(359, 1, 6) (359,) (60, 1, 6) (60,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = split_train_test(reframed_data, n_train_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 15)"
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.loc[time_pairs[0][0]:time_pairs[0][3],:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "359/359 [==============================] - 4s 11ms/step - loss: 0.2835\n",
      "Epoch 2/50\n",
      "359/359 [==============================] - 0s 41us/step - loss: 0.2733\n",
      "Epoch 3/50\n",
      "359/359 [==============================] - 0s 47us/step - loss: 0.2633\n",
      "Epoch 4/50\n",
      "359/359 [==============================] - 0s 49us/step - loss: 0.2536\n",
      "Epoch 5/50\n",
      "359/359 [==============================] - 0s 46us/step - loss: 0.2440\n",
      "Epoch 6/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.2347\n",
      "Epoch 7/50\n",
      "359/359 [==============================] - 0s 34us/step - loss: 0.2257\n",
      "Epoch 8/50\n",
      "359/359 [==============================] - 0s 43us/step - loss: 0.2169\n",
      "Epoch 9/50\n",
      "359/359 [==============================] - 0s 35us/step - loss: 0.2083\n",
      "Epoch 10/50\n",
      "359/359 [==============================] - 0s 35us/step - loss: 0.2000\n",
      "Epoch 11/50\n",
      "359/359 [==============================] - 0s 36us/step - loss: 0.1920\n",
      "Epoch 12/50\n",
      "359/359 [==============================] - 0s 38us/step - loss: 0.1842\n",
      "Epoch 13/50\n",
      "359/359 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 14/50\n",
      "359/359 [==============================] - 0s 44us/step - loss: 0.1693\n",
      "Epoch 15/50\n",
      "359/359 [==============================] - 0s 38us/step - loss: 0.1622\n",
      "Epoch 16/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.1554\n",
      "Epoch 17/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.1488\n",
      "Epoch 18/50\n",
      "359/359 [==============================] - 0s 42us/step - loss: 0.1425\n",
      "Epoch 19/50\n",
      "359/359 [==============================] - 0s 38us/step - loss: 0.1364\n",
      "Epoch 20/50\n",
      "359/359 [==============================] - 0s 38us/step - loss: 0.1306\n",
      "Epoch 21/50\n",
      "359/359 [==============================] - 0s 38us/step - loss: 0.1250\n",
      "Epoch 22/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.1197\n",
      "Epoch 23/50\n",
      "359/359 [==============================] - 0s 35us/step - loss: 0.1145\n",
      "Epoch 24/50\n",
      "359/359 [==============================] - 0s 34us/step - loss: 0.1097\n",
      "Epoch 25/50\n",
      "359/359 [==============================] - 0s 36us/step - loss: 0.1050\n",
      "Epoch 26/50\n",
      "359/359 [==============================] - 0s 41us/step - loss: 0.1006\n",
      "Epoch 27/50\n",
      "359/359 [==============================] - 0s 42us/step - loss: 0.0965\n",
      "Epoch 28/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.0925\n",
      "Epoch 29/50\n",
      "359/359 [==============================] - 0s 40us/step - loss: 0.0888\n",
      "Epoch 30/50\n",
      "359/359 [==============================] - 0s 40us/step - loss: 0.0853\n",
      "Epoch 31/50\n",
      "359/359 [==============================] - 0s 41us/step - loss: 0.0820\n",
      "Epoch 32/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.0789\n",
      "Epoch 33/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0761\n",
      "Epoch 34/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.0734\n",
      "Epoch 35/50\n",
      "359/359 [==============================] - 0s 39us/step - loss: 0.0709\n",
      "Epoch 36/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0686\n",
      "Epoch 37/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0664\n",
      "Epoch 38/50\n",
      "359/359 [==============================] - 0s 38us/step - loss: 0.0644\n",
      "Epoch 39/50\n",
      "359/359 [==============================] - ETA: 0s - loss: 0.028 - 0s 35us/step - loss: 0.0626\n",
      "Epoch 40/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0609\n",
      "Epoch 41/50\n",
      "359/359 [==============================] - 0s 36us/step - loss: 0.0594\n",
      "Epoch 42/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0580\n",
      "Epoch 43/50\n",
      "359/359 [==============================] - 0s 44us/step - loss: 0.0567\n",
      "Epoch 44/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0556\n",
      "Epoch 45/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0545\n",
      "Epoch 46/50\n",
      "359/359 [==============================] - 0s 41us/step - loss: 0.0536\n",
      "Epoch 47/50\n",
      "359/359 [==============================] - 0s 36us/step - loss: 0.0527\n",
      "Epoch 48/50\n",
      "359/359 [==============================] - 0s 36us/step - loss: 0.0519\n",
      "Epoch 49/50\n",
      "359/359 [==============================] - 0s 37us/step - loss: 0.0512\n",
      "Epoch 50/50\n",
      "359/359 [==============================] - 0s 41us/step - loss: 0.0506\n"
     ]
    }
   ],
   "source": [
    "df1_model = create_LSTM(train_X, train_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions with LSTM model\n",
    "def model_predict(model, test_X, n_features, scaler):\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    inv_yhat = np.concatenate([yhat, test_X], axis=1)[:,:n_features]\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)[:,0]\n",
    "    return inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat = model_predict(df1_model, test_X, n_features, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_yhat.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join predictions to dataframe\n",
    "df1_1.loc[time_pairs[0][2]:time_pairs[0][3], 'Value'] = inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>isHoliday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-09-03</th>\n",
       "      <td>9.096555e+05</td>\n",
       "      <td>19.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-04</th>\n",
       "      <td>1.748273e+06</td>\n",
       "      <td>21.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-05</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>23.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-06</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>21.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-07</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-08</th>\n",
       "      <td>1.964878e+06</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-09</th>\n",
       "      <td>3.266904e+06</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-10</th>\n",
       "      <td>2.926094e+06</td>\n",
       "      <td>19.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-11</th>\n",
       "      <td>1.720502e+06</td>\n",
       "      <td>23.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-12</th>\n",
       "      <td>1.136248e+06</td>\n",
       "      <td>12.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-13</th>\n",
       "      <td>1.040529e+06</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-14</th>\n",
       "      <td>1.030668e+06</td>\n",
       "      <td>9.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-15</th>\n",
       "      <td>1.226753e+06</td>\n",
       "      <td>11.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-16</th>\n",
       "      <td>1.228874e+06</td>\n",
       "      <td>12.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-17</th>\n",
       "      <td>1.169026e+06</td>\n",
       "      <td>13.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-18</th>\n",
       "      <td>1.513722e+06</td>\n",
       "      <td>11.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-19</th>\n",
       "      <td>2.015528e+06</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-20</th>\n",
       "      <td>2.548943e+06</td>\n",
       "      <td>13.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-21</th>\n",
       "      <td>4.235358e+06</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-22</th>\n",
       "      <td>5.538000e+06</td>\n",
       "      <td>10.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-23</th>\n",
       "      <td>6.145531e+06</td>\n",
       "      <td>10.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-24</th>\n",
       "      <td>5.536844e+06</td>\n",
       "      <td>13.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-25</th>\n",
       "      <td>4.212580e+06</td>\n",
       "      <td>15.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-26</th>\n",
       "      <td>4.778401e+06</td>\n",
       "      <td>14.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-27</th>\n",
       "      <td>5.907855e+06</td>\n",
       "      <td>15.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-28</th>\n",
       "      <td>4.677118e+06</td>\n",
       "      <td>15.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-29</th>\n",
       "      <td>2.470595e+06</td>\n",
       "      <td>15.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-30</th>\n",
       "      <td>2.676795e+06</td>\n",
       "      <td>18.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-01</th>\n",
       "      <td>2.445638e+06</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-02</th>\n",
       "      <td>2.358238e+06</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-28</th>\n",
       "      <td>3.964284e+06</td>\n",
       "      <td>20.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-29</th>\n",
       "      <td>3.969980e+06</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-30</th>\n",
       "      <td>4.021693e+06</td>\n",
       "      <td>14.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-01</th>\n",
       "      <td>3.943967e+06</td>\n",
       "      <td>13.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-02</th>\n",
       "      <td>3.780612e+06</td>\n",
       "      <td>11.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-03</th>\n",
       "      <td>3.723357e+06</td>\n",
       "      <td>10.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-04</th>\n",
       "      <td>3.669174e+06</td>\n",
       "      <td>9.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-05</th>\n",
       "      <td>3.601333e+06</td>\n",
       "      <td>13.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-06</th>\n",
       "      <td>3.618350e+06</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-07</th>\n",
       "      <td>3.756566e+06</td>\n",
       "      <td>14.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-08</th>\n",
       "      <td>3.759784e+06</td>\n",
       "      <td>12.55</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-09</th>\n",
       "      <td>3.779292e+06</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-10</th>\n",
       "      <td>3.791191e+06</td>\n",
       "      <td>10.70</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-11</th>\n",
       "      <td>3.890939e+06</td>\n",
       "      <td>11.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-12</th>\n",
       "      <td>3.648826e+06</td>\n",
       "      <td>16.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-13</th>\n",
       "      <td>3.735232e+06</td>\n",
       "      <td>19.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-14</th>\n",
       "      <td>3.898845e+06</td>\n",
       "      <td>12.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-15</th>\n",
       "      <td>3.912180e+06</td>\n",
       "      <td>7.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-16</th>\n",
       "      <td>3.631139e+06</td>\n",
       "      <td>10.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-17</th>\n",
       "      <td>3.506682e+06</td>\n",
       "      <td>5.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-18</th>\n",
       "      <td>3.543725e+06</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-19</th>\n",
       "      <td>3.370804e+06</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-20</th>\n",
       "      <td>3.336974e+06</td>\n",
       "      <td>15.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-21</th>\n",
       "      <td>3.478164e+06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-22</th>\n",
       "      <td>3.853221e+06</td>\n",
       "      <td>19.10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-23</th>\n",
       "      <td>3.893227e+06</td>\n",
       "      <td>10.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-24</th>\n",
       "      <td>3.884861e+06</td>\n",
       "      <td>12.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-25</th>\n",
       "      <td>3.640445e+06</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-26</th>\n",
       "      <td>3.724437e+06</td>\n",
       "      <td>8.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-27</th>\n",
       "      <td>3.719725e+06</td>\n",
       "      <td>8.70</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Value  Temperature  isHoliday\n",
       "Timestamp                                       \n",
       "2014-09-03  9.096555e+05        19.60        0.0\n",
       "2014-09-04  1.748273e+06        21.30        0.0\n",
       "2014-09-05  0.000000e+00        23.35        0.0\n",
       "2014-09-06  0.000000e+00        21.60        0.0\n",
       "2014-09-07  0.000000e+00        15.80        0.0\n",
       "2014-09-08  1.964878e+06        15.25        0.0\n",
       "2014-09-09  3.266904e+06        19.15        0.0\n",
       "2014-09-10  2.926094e+06        19.25        0.0\n",
       "2014-09-11  1.720502e+06        23.55        0.0\n",
       "2014-09-12  1.136248e+06        12.05        0.0\n",
       "2014-09-13  1.040529e+06        14.05        0.0\n",
       "2014-09-14  1.030668e+06         9.05        0.0\n",
       "2014-09-15  1.226753e+06        11.10        0.0\n",
       "2014-09-16  1.228874e+06        12.60        0.0\n",
       "2014-09-17  1.169026e+06        13.10        0.0\n",
       "2014-09-18  1.513722e+06        11.75        0.0\n",
       "2014-09-19  2.015528e+06         9.60        0.0\n",
       "2014-09-20  2.548943e+06        13.10        0.0\n",
       "2014-09-21  4.235358e+06        18.10        0.0\n",
       "2014-09-22  5.538000e+06        10.75        0.0\n",
       "2014-09-23  6.145531e+06        10.65        0.0\n",
       "2014-09-24  5.536844e+06        13.05        0.0\n",
       "2014-09-25  4.212580e+06        15.20        0.0\n",
       "2014-09-26  4.778401e+06        14.20        0.0\n",
       "2014-09-27  5.907855e+06        15.65        0.0\n",
       "2014-09-28  4.677118e+06        15.90        0.0\n",
       "2014-09-29  2.470595e+06        15.65        0.0\n",
       "2014-09-30  2.676795e+06        18.05        0.0\n",
       "2014-10-01  2.445638e+06        12.00        0.0\n",
       "2014-10-02  2.358238e+06        14.85        0.0\n",
       "...                  ...          ...        ...\n",
       "2015-09-28  3.964284e+06        20.35        0.0\n",
       "2015-09-29  3.969980e+06        19.50        0.0\n",
       "2015-09-30  4.021693e+06        14.50        0.0\n",
       "2015-10-01  3.943967e+06        13.05        0.0\n",
       "2015-10-02  3.780612e+06        11.95        0.0\n",
       "2015-10-03  3.723357e+06        10.30        0.0\n",
       "2015-10-04  3.669174e+06         9.05        0.0\n",
       "2015-10-05  3.601333e+06        13.65        0.0\n",
       "2015-10-06  3.618350e+06        13.20        0.0\n",
       "2015-10-07  3.756566e+06        14.65        0.0\n",
       "2015-10-08  3.759784e+06        12.55        0.0\n",
       "2015-10-09  3.779292e+06        19.15        0.0\n",
       "2015-10-10  3.791191e+06        10.70        0.0\n",
       "2015-10-11  3.890939e+06        11.85        0.0\n",
       "2015-10-12  3.648826e+06        16.10        0.0\n",
       "2015-10-13  3.735232e+06        19.35        0.0\n",
       "2015-10-14  3.898845e+06        12.05        0.0\n",
       "2015-10-15  3.912180e+06         7.00        0.0\n",
       "2015-10-16  3.631139e+06        10.05        0.0\n",
       "2015-10-17  3.506682e+06         5.20        0.0\n",
       "2015-10-18  3.543725e+06         4.40        0.0\n",
       "2015-10-19  3.370804e+06         3.95        0.0\n",
       "2015-10-20  3.336974e+06        15.80        0.0\n",
       "2015-10-21  3.478164e+06        16.00        0.0\n",
       "2015-10-22  3.853221e+06        19.10        0.0\n",
       "2015-10-23  3.893227e+06        10.30        0.0\n",
       "2015-10-24  3.884861e+06        12.20        0.0\n",
       "2015-10-25  3.640445e+06        14.25        0.0\n",
       "2015-10-26  3.724437e+06         8.60        0.0\n",
       "2015-10-27  3.719725e+06         8.70        0.0\n",
       "\n",
       "[420 rows x 3 columns]"
      ]
     },
     "execution_count": 1102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adds prediction to proper submission format\n",
    "def predict_site(train=None, test=None, site_id=None):\n",
    "    #load site data and train/test times\n",
    "    data = load_site(train, test, site_id)\n",
    "    data.sort_values('Timestamp', inplace=True)\n",
    "    data.index = data.Timestamp\n",
    "    data = prepare_data(data, features=['Value', 'Temperature','isHoliday','ForecastId','Timestamp'])\n",
    "    time_pairs = find_start_end(data)\n",
    "    \n",
    "    #build model and predict for each forecastid\n",
    "    for n, times in enumerate(time_pairs):\n",
    "        df = data[(data.Timestamp >= time_pairs[n][0]) & (data.Timestamp <= time_pairs[n][3])]\n",
    "        df = prepare_data(df, features=['Value','Temperature','isHoliday','ForecastId'])\n",
    "        df['Temperature'].fillna(0, inplace=True)\n",
    "        df.loc[:,'Timestamp'] = df.index\n",
    "        df.drop(['ForecastId','Timestamp'],axis=1, inplace=True)\n",
    "        n_train_days = df[(df.index >=time_pairs[n][0]) & (df.index <=time_pairs[n][1])].shape[0]-1\n",
    "        n_features = df.shape[1]\n",
    "        reframed_data, scaler = reframe_features(df, 2)\n",
    "        reframed_data.fillna(0, inplace=True)\n",
    "        train_X, train_y, test_X, test_y = split_train_test(reframed_data, n_train_days)\n",
    "        model = create_LSTM(train_X, train_y, epochs=50)\n",
    "        inv_yhat = model_predict(model, test_X, n_features, scaler)\n",
    "        data.loc[time_pairs[n][2]:time_pairs[n][3], 'Value'] = inv_yhat\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add features from metadata to site data\n",
    "def add_meta(data, site_id):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
