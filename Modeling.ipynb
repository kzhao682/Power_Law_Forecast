{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from starter import *\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "holidays = pd.read_csv('holidays.csv')\n",
    "weather = pd.read_csv('weather.csv')\n",
    "metadata = pd.read_csv('metadata.csv')\n",
    "submission_format = pd.read_csv('submission_format.csv')\n",
    "submission_frequency = pd.read_csv('submission_frequency.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_frequency = pickle.load(open('submission_frequency.p', 'rb'))\n",
    "metadata = pickle.load(open('metadata.p', 'rb'))\n",
    "holidays = pickle.load(open('holidays.p', 'rb'))\n",
    "weather_grouped = pickle.load(open('weather_grouped.p', 'rb'))\n",
    "train = pickle.load(open('train.p', 'rb'))\n",
    "submission_format = pickle.load(open('submission_format.p', 'rb'))\n",
    "df = pickle.load(open('df.p', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Holiday'].fillna(0, inplace=True)\n",
    "df['isHoliday'].fillna(0, inplace=True)\n",
    "df.drop(['Unnamed: 0_x','Unnamed: 0_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_id</th>\n",
       "      <th>SiteId</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Value</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Hour</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>isHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>744519</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>9.096555e+05</td>\n",
       "      <td>2014-09-03</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>19.60</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7627564</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>1.748273e+06</td>\n",
       "      <td>2014-09-04</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>21.30</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7034705</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>23.35</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5995486</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-09-06</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>21.60</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7326510</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-09-07</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>15.80</td>\n",
       "      <td>22.921092</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    obs_id  SiteId  Timestamp         Value        Date      Time  Hour  \\\n",
       "0   744519       1 2014-09-03  9.096555e+05  2014-09-03  00:00:00     0   \n",
       "1  7627564       1 2014-09-04  1.748273e+06  2014-09-04  00:00:00     0   \n",
       "2  7034705       1 2014-09-05  0.000000e+00  2014-09-05  00:00:00     0   \n",
       "3  5995486       1 2014-09-06  0.000000e+00  2014-09-06  00:00:00     0   \n",
       "4  7326510       1 2014-09-07  0.000000e+00  2014-09-07  00:00:00     0   \n",
       "\n",
       "   DayofWeek  Year  Month  Temperature   Distance  Holiday  isHoliday  \n",
       "0  Wednesday  2014      9        19.60  22.921092        0        0.0  \n",
       "1   Thursday  2014      9        21.30  22.921092        0        0.0  \n",
       "2     Friday  2014      9        23.35  22.921092        0        0.0  \n",
       "3   Saturday  2014      9        21.60  22.921092        0        0.0  \n",
       "4     Sunday  2014      9        15.80  22.921092        0        0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>ForecastPeriodNS</th>\n",
       "      <th>ForecastPeriodMin</th>\n",
       "      <th>Period_Quarter</th>\n",
       "      <th>Period_Hour</th>\n",
       "      <th>Period_Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>86400000000000</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3600000000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastId  ForecastPeriodNS  ForecastPeriodMin  Period_Quarter  \\\n",
       "0           1    86400000000000             1440.0               0   \n",
       "1           2    86400000000000             1440.0               0   \n",
       "2           3    86400000000000             1440.0               0   \n",
       "3           4    86400000000000             1440.0               0   \n",
       "4           5     3600000000000               60.0               0   \n",
       "\n",
       "   Period_Hour  Period_Days  \n",
       "0            0            1  \n",
       "1            0            1  \n",
       "2            0            1  \n",
       "3            0            1  \n",
       "4            1            0  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_frequency.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align SiteId to ForecastId\n",
    "id_align = submission_format.groupby(by = 'ForecastId').mean()\n",
    "id_align['ForecastId'] = id_align.index\n",
    "id_align.drop(['obs_id', 'Value'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_frequency = submission_frequency.merge(id_align, how='left', on='ForecastId')\n",
    "site_type = submission_frequency.groupby(by='SiteId').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SiteId</th>\n",
       "      <th>Surface</th>\n",
       "      <th>Sampling</th>\n",
       "      <th>BaseTemperature</th>\n",
       "      <th>MondayIsDayOff</th>\n",
       "      <th>TuesdayIsDayOff</th>\n",
       "      <th>WednesdayIsDayOff</th>\n",
       "      <th>ThursdayIsDayOff</th>\n",
       "      <th>FridayIsDayOff</th>\n",
       "      <th>SaturdayIsDayOff</th>\n",
       "      <th>SundayIsDayOff</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SiteId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1387.205119</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6098.278376</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10556.293605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12541.181277</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>9150.195373</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SiteId       Surface  Sampling  BaseTemperature MondayIsDayOff  \\\n",
       "SiteId                                                                   \n",
       "1            1   1387.205119      15.0             18.0              0   \n",
       "2            2   6098.278376      30.0             18.0              0   \n",
       "3            3  10556.293605       5.0             18.0              0   \n",
       "5            5  12541.181277      30.0             18.0              0   \n",
       "6            6   9150.195373      30.0             18.0              0   \n",
       "\n",
       "       TuesdayIsDayOff WednesdayIsDayOff ThursdayIsDayOff  FridayIsDayOff  \\\n",
       "SiteId                                                                      \n",
       "1                    0                 0                0               0   \n",
       "2                    0                 0                0               0   \n",
       "3                    0                 0                0               0   \n",
       "5                    0                 0                0               0   \n",
       "6                    0                 0                0               0   \n",
       "\n",
       "        SaturdayIsDayOff  SundayIsDayOff  Temperature  \n",
       "SiteId                                                 \n",
       "1                      1               1            0  \n",
       "2                      1               1            0  \n",
       "3                      1               0            0  \n",
       "5                      1               1            0  \n",
       "6                      1               1            0  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(y, pred):\n",
    "    return mean_squared_error(y, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire siteid data\n",
    "def get_site_data(data=None, site_id=None, features=['Value','Temperature']):\n",
    "    df = data[data.SiteId==site_id]\n",
    "    df.index = df.Timestamp\n",
    "    df = df[features]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment and interpolate data\n",
    "def prepare_site(data=None, site_id=None, features= ['Value', 'Temperature'], method='linear'):\n",
    "    df = get_site_data(data, site_id, features)\n",
    "    try:\n",
    "        # start where there isn't consecutive NaNs\n",
    "        start_index = df[(df.Temperature.isnull()==False)&(df.Temperature.shift(-1).isnull()==False)].index[0]\n",
    "        df = df.loc[start_index:,:]\n",
    "        df['Temperature'].interpolate(method, inplace=True)\n",
    "    except:\n",
    "        print('No temperature data')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2=prepare_site(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_master_data(data=None, sites=None, features=['Value', 'Temperature'], method='linear'):\n",
    "    master_df = pd.DataFrame()\n",
    "    for site in sites:\n",
    "        threshold_size = data[data.SiteId==site].shape[0]*0.5\n",
    "        site_features = features.copy()\n",
    "        if data[data.SiteId==site].Temperature.isnull().value_counts()[0] < threshold_size:\n",
    "            site_features.remove('Temperature')\n",
    "        df = prepare_site(data, site, site_features)\n",
    "        print('Finished site {} with rows {}'.format(site, df.shape[0]))\n",
    "        master_df = pd.concat([master_df, df], axis=0)\n",
    "    print('Final rows: {}'.format(master_df.shape[0]))\n",
    "    return master_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and reframe features\n",
    "def reframe_features(data=None, n_in=1):\n",
    "    values = data.values\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, n_in, 1)\n",
    "    reframed.drop(reframed.columns[[reframed.shape[1] - i for i in range(1,data.shape[1])]], axis=1, inplace=True)\n",
    "    print(reframed.head())\n",
    "    return reframed, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-2)  var2(t-2)  var1(t-1)  var2(t-1)   var1(t)\n",
      "2   0.201850   0.763602   0.222406   0.769231  0.215942\n",
      "3   0.222406   0.769231   0.215942   0.769231  0.180349\n",
      "4   0.215942   0.769231   0.180349   0.795497  0.167053\n",
      "5   0.180349   0.795497   0.167053   0.769231  0.179651\n",
      "6   0.167053   0.769231   0.179651   0.769231  0.157865\n"
     ]
    }
   ],
   "source": [
    "reframed_data = reframe_features(df2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train/test sets from reframed data\n",
    "def split_train_test_val(reframed):\n",
    "    values = reframed.values\n",
    "    n_train_days = int(len(values) * 0.7)\n",
    "    train = values[:n_train_days, :]\n",
    "    test = values[n_train_days:, :]\n",
    "    # Split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    # Reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24283, 1, 4) (24283,) (10407, 1, 4) (10407,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = split_train_test_val(reframed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build multivariate LSTM model with validation\n",
    "def create_LSTM_val(train_X=None, train_y=None, test_X=None, test_y=None, epochs=50, batch_size=100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=epochs,\n",
    "                                batch_size=batch_size, validation_data=(test_X, test_y),\n",
    "                                verbose=1, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24283 samples, validate on 10407 samples\n",
      "Epoch 1/50\n",
      "24283/24283 [==============================] - 3s 108us/step - loss: 0.0663 - val_loss: 0.0045\n",
      "Epoch 2/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0201 - val_loss: 0.0032\n",
      "Epoch 3/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0122 - val_loss: 0.0025\n",
      "Epoch 4/50\n",
      "24283/24283 [==============================] - 1s 24us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 5/50\n",
      "24283/24283 [==============================] - 1s 24us/step - loss: 0.0078 - val_loss: 0.0027\n",
      "Epoch 6/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 7/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 9/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 10/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 11/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 12/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 13/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 14/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 15/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 16/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 17/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 18/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 20/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 21/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 22/50\n",
      "24283/24283 [==============================] - 1s 29us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "24283/24283 [==============================] - 1s 28us/step - loss: 0.0030 - val_loss: 9.6923e-04\n",
      "Epoch 24/50\n",
      "24283/24283 [==============================] - 1s 28us/step - loss: 0.0029 - val_loss: 8.8340e-04\n",
      "Epoch 25/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0029 - val_loss: 8.2869e-04\n",
      "Epoch 26/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0029 - val_loss: 7.9435e-04\n",
      "Epoch 27/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0028 - val_loss: 7.7247e-04\n",
      "Epoch 28/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.5807e-04\n",
      "Epoch 29/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0028 - val_loss: 7.4824e-04\n",
      "Epoch 30/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.4129e-04\n",
      "Epoch 31/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.3627e-04\n",
      "Epoch 32/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0028 - val_loss: 7.3259e-04\n",
      "Epoch 33/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2990e-04\n",
      "Epoch 34/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0028 - val_loss: 7.2796e-04\n",
      "Epoch 35/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2659e-04\n",
      "Epoch 36/50\n",
      "24283/24283 [==============================] - 1s 27us/step - loss: 0.0028 - val_loss: 7.2566e-04\n",
      "Epoch 37/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2506e-04\n",
      "Epoch 38/50\n",
      "24283/24283 [==============================] - 1s 26us/step - loss: 0.0028 - val_loss: 7.2472e-04\n",
      "Epoch 39/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2456e-04\n",
      "Epoch 40/50\n",
      "24283/24283 [==============================] - 1s 29us/step - loss: 0.0028 - val_loss: 7.2456e-04\n",
      "Epoch 41/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2466e-04\n",
      "Epoch 42/50\n",
      "24283/24283 [==============================] - 1s 22us/step - loss: 0.0028 - val_loss: 7.2483e-04\n",
      "Epoch 43/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2507e-04\n",
      "Epoch 44/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2534e-04\n",
      "Epoch 45/50\n",
      "24283/24283 [==============================] - 1s 24us/step - loss: 0.0028 - val_loss: 7.2564e-04\n",
      "Epoch 46/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2595e-04\n",
      "Epoch 47/50\n",
      "24283/24283 [==============================] - 1s 23us/step - loss: 0.0028 - val_loss: 7.2627e-04\n",
      "Epoch 48/50\n",
      "24283/24283 [==============================] - 1s 25us/step - loss: 0.0028 - val_loss: 7.2660e-04\n",
      "Epoch 49/50\n",
      "24283/24283 [==============================] - 1s 26us/step - loss: 0.0028 - val_loss: 7.2692e-04\n",
      "Epoch 50/50\n",
      "24283/24283 [==============================] - 1s 26us/step - loss: 0.0028 - val_loss: 7.2724e-04\n"
     ]
    }
   ],
   "source": [
    "multi_model = create_LSTM_val(train_X, train_y, test_X, test_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = multi_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare forecast to actual\n",
    "def forecast_score(pred, actual_input, actual_output):\n",
    "    actual_input = actual_input.reshape((actual_input.shape[0], actual_input.shape[2]))\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    inv_pred = np.concatenate((pred, actual_input[:, 1:]), axis=1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler.fit(inv_pred)\n",
    "    inv_pred = scaler.inverse_transform(inv_pred)\n",
    "    inv_pred = inv_pred[:,0]\n",
    "    \n",
    "    # Invert scaling for actual\n",
    "    actual_output = actual_output.reshape((len(actual_output), 1))\n",
    "    inv_output = np.concatenate((actual_output, actual_input[:, 1:]), axis=1)\n",
    "    inv_output = scaler.inverse_transform(inv_output)\n",
    "    inv_output = inv_output[:,0]\n",
    "    rmsle = RMSE(inv_output, inv_pred)\n",
    "    \n",
    "    return rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016920891150341268"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_score(yhat, test_X, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for site prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate train and test sets\n",
    "def load_site(train=None, test=None, site_id=None, weather=weather_grouped, holidays=holidays):\n",
    "    train = train[train.SiteId==site_id]\n",
    "    test = test[test.SiteId==site_id]\n",
    "    train.loc[:,'ForecastId'] = 0\n",
    "    df = pd.concat([train, test], axis=0)\n",
    "    df = df.merge(weather, how='left', on=['Timestamp', 'SiteId'])\n",
    "    df = df.merge(holidays, how='left', on=['Date','SiteId'])\n",
    "    df['Holiday'].fillna(0, inplace=True)\n",
    "    df['isHoliday'].fillna(0, inplace=True)\n",
    "    df.drop(['Unnamed: 0_x','Unnamed: 0_y'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = load_site(train, submission_format,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# segment and interpolate data for site\n",
    "def prepare_data(data=None, features= ['Value', 'Temperature'], method='linear'):\n",
    "    data.index = data.Timestamp\n",
    "    data = data[features]\n",
    "    try:\n",
    "        # start where there isn't consecutive NaNs\n",
    "        start_index = data[(data.Temperature.isnull()==False)&(data.Temperature.shift(-1).isnull()==False)].index[0]\n",
    "        data = data.loc[start_index:,:]\n",
    "        data['Temperature'].interpolate(method, inplace=True)\n",
    "    except:\n",
    "        print('No temperature data')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = prepare_data(df1, features=['Value','Temperature','isHoliday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-2)  var2(t-2)  var3(t-2)  var1(t-1)  var2(t-1)  var3(t-1)   var1(t)\n",
      "2   0.090837   0.825079        0.0   0.174579   0.860906        0.0  0.000000\n",
      "3   0.174579   0.860906        0.0   0.000000   0.904110        0.0  0.000000\n",
      "4   0.000000   0.904110        0.0   0.000000   0.867229        0.0  0.000000\n",
      "5   0.000000   0.867229        0.0   0.000000   0.744995        0.0  0.196209\n",
      "6   0.000000   0.744995        0.0   0.196209   0.733404        0.0  0.326227\n"
     ]
    }
   ],
   "source": [
    "n_train_days = train[train.SiteId==1].shape[0]-1\n",
    "reframed_data, scaler = reframe_features(df1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899, 1, 6) (899,) (236, 1, 6) (236,)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y, test_X, test_y = split_train_test(reframed_data, n_train_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_days = train[train.SiteId==1].shape[0]-1\n",
    "n_features = df1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train/test sets from reframed data\n",
    "def split_train_test(reframed, n_train_days):\n",
    "    values = reframed.values\n",
    "    train = values[:n_train_days, :]\n",
    "    test = values[n_train_days+1:, :]\n",
    "    # Split into input and outputs\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    # Reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    return train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build multivariate LSTM model for predictions\n",
    "def create_LSTM_pred(train_X=None, train_y=None, epochs=50, batch_size=100):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                verbose=1, shuffle=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "899/899 [==============================] - 3s 3ms/step - loss: 0.3428\n",
      "Epoch 2/50\n",
      "899/899 [==============================] - 0s 36us/step - loss: 0.3138\n",
      "Epoch 3/50\n",
      "899/899 [==============================] - 0s 33us/step - loss: 0.2863\n",
      "Epoch 4/50\n",
      "899/899 [==============================] - 0s 26us/step - loss: 0.2604\n",
      "Epoch 5/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.2363\n",
      "Epoch 6/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.2140\n",
      "Epoch 7/50\n",
      "899/899 [==============================] - 0s 27us/step - loss: 0.1933\n",
      "Epoch 8/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.1744\n",
      "Epoch 9/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.1571\n",
      "Epoch 10/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.1414\n",
      "Epoch 11/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.1274\n",
      "Epoch 12/50\n",
      "899/899 [==============================] - 0s 27us/step - loss: 0.1148\n",
      "Epoch 13/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.1038\n",
      "Epoch 14/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.0941\n",
      "Epoch 15/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0858\n",
      "Epoch 16/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0786\n",
      "Epoch 17/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.0726\n",
      "Epoch 18/50\n",
      "899/899 [==============================] - 0s 26us/step - loss: 0.0676\n",
      "Epoch 19/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.0635\n",
      "Epoch 20/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.0602\n",
      "Epoch 21/50\n",
      "899/899 [==============================] - 0s 27us/step - loss: 0.0575\n",
      "Epoch 22/50\n",
      "899/899 [==============================] - 0s 27us/step - loss: 0.0553\n",
      "Epoch 23/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.0536\n",
      "Epoch 24/50\n",
      "899/899 [==============================] - 0s 31us/step - loss: 0.0522\n",
      "Epoch 25/50\n",
      "899/899 [==============================] - 0s 32us/step - loss: 0.0511\n",
      "Epoch 26/50\n",
      "899/899 [==============================] - 0s 27us/step - loss: 0.0502\n",
      "Epoch 27/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0495\n",
      "Epoch 28/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.0489\n",
      "Epoch 29/50\n",
      "899/899 [==============================] - 0s 29us/step - loss: 0.0484\n",
      "Epoch 30/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0479\n",
      "Epoch 31/50\n",
      "899/899 [==============================] - 0s 31us/step - loss: 0.0475\n",
      "Epoch 32/50\n",
      "899/899 [==============================] - 0s 32us/step - loss: 0.0471\n",
      "Epoch 33/50\n",
      "899/899 [==============================] - 0s 33us/step - loss: 0.0467\n",
      "Epoch 34/50\n",
      "899/899 [==============================] - 0s 32us/step - loss: 0.0463\n",
      "Epoch 35/50\n",
      "899/899 [==============================] - 0s 33us/step - loss: 0.0460\n",
      "Epoch 36/50\n",
      "899/899 [==============================] - 0s 38us/step - loss: 0.0456\n",
      "Epoch 37/50\n",
      "899/899 [==============================] - 0s 41us/step - loss: 0.0452\n",
      "Epoch 38/50\n",
      "899/899 [==============================] - 0s 32us/step - loss: 0.0449\n",
      "Epoch 39/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0445\n",
      "Epoch 40/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0442\n",
      "Epoch 41/50\n",
      "899/899 [==============================] - 0s 33us/step - loss: 0.0438\n",
      "Epoch 42/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0435\n",
      "Epoch 43/50\n",
      "899/899 [==============================] - 0s 31us/step - loss: 0.0431\n",
      "Epoch 44/50\n",
      "899/899 [==============================] - 0s 31us/step - loss: 0.0428\n",
      "Epoch 45/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.0425\n",
      "Epoch 46/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.0421\n",
      "Epoch 47/50\n",
      "899/899 [==============================] - 0s 30us/step - loss: 0.0418\n",
      "Epoch 48/50\n",
      "899/899 [==============================] - 0s 27us/step - loss: 0.0415\n",
      "Epoch 49/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.0411\n",
      "Epoch 50/50\n",
      "899/899 [==============================] - 0s 28us/step - loss: 0.0408\n"
     ]
    }
   ],
   "source": [
    "df1_model = create_LSTM_pred(train_X, train_y, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make predictions with LSTM model\n",
    "def model_predict(model, test_X, n_features):\n",
    "    yhat = model.predict(test_X)\n",
    "    test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "    inv_yhat = np.concatenate([yhat, test_X], axis=1)[:,:n_features]\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)[:,0]\n",
    "    return inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_yhat = model_predict(df1_model, test_X, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add features from metadata to site data\n",
    "def add_meta(data, site_id):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
